{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2df60ec0-ecc5-431b-9f3c-c1f8b93cd4ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_nyc_taxi = spark.read.parquet(\n",
    "    \"/FileStore/tables/yellow_tripdata_2016_01.parquet\",\n",
    "    \"/FileStore/tables/yellow_tripdata_2016_02.parquet\",\n",
    "    \"/FileStore/tables/yellow_tripdata_2016_03.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "870668e9-8777-4877-a598-b3eadcba1056",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_nyc_taxi.display()\n",
    "df_nyc_taxi.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54a2be4c-7d8f-48c1-a8db-dfd5332aa0ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_zone_lookup=spark.read.format('csv').option(\"header\",True).option('inferSchema',True).load('/FileStore/tables/taxi_zone_lookup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0a06829-4467-4009-8962-561d5ccd518f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_zone_lookup.display()\n",
    "df_zone_lookup.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6abddb91-c97e-4be0-ac10-6b13dfd57f63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_zone_lookup_filled =  df_zone_lookup.replace(\"N/A\", \"Unknown\").fillna(\"Unknown\")\n",
    "df_zone_lookup_filled.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6694e523-c4ec-4918-be5b-7f8e8006a4ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "168d8942-cdd2-4d8f-93ee-2a2338554f65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_zone_lookup_PU=df_zone_lookup.select([col(c).alias(f\"PU{c}\") if c != \"LocationID\" else col(c).alias(\"PULocationID\") for c in df_zone_lookup.columns])\n",
    "df_zone_lookup_DO=df_zone_lookup.select([col(c).alias(f\"DO{c}\") if c != \"LocationID\" else col(c).alias(\"DOLocationID\") for c in df_zone_lookup.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13de2888-988d-4018-93be-3573e1047819",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Join pickup location data\n",
    "df_joined = df_nyc_taxi.join(df_zone_lookup_PU, on=\"PULocationID\", how=\"left\")\n",
    "\n",
    "# Join dropoff location data\n",
    "df_joined = df_joined.join(df_zone_lookup_DO, on=\"DOLocationID\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc89bf01-45e8-4432-83ae-b2fe8f3bc155",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Total data:\", df_joined.count())\n",
    "df_joined.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a09eef6d-5c55-416e-8ddc-7fb55aae89b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install missingno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eef36487-cae3-40c5-9376-1d55843d946c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import missingno as msno\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67720d7e-489a-4cb7-824b-377a4ca10a6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convert PySpark DataFrame to Pandas (be careful with large datasets)\n",
    "df_pd = df_joined.limit(10000).toPandas()  # limit rows to avoid memory issues\n",
    "\n",
    "# Plot missing values matrix\n",
    "msno.matrix(df_pd, figsize=(20, 6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6bf0f826-2c0d-49b7-946d-318b544f5d96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Plot heatmap of null correlations\n",
    "msno.heatmap(df_pd, figsize=(10, 5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ac78202-b142-427e-93e2-93f1ea2c9138",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "columns_to_drop = [\n",
    "    'congestion_surcharge','airport_fee'\n",
    "]\n",
    "\n",
    "df_joined = df_joined.drop(*columns_to_drop)\n",
    "\n",
    "print(\"Total data:\", df_joined.count())\n",
    "# df_joined.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9f02af2-6fbd-4f2e-afc0-88f085e67a93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Compute and plot Spearman correlation\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.heatmap(df_pd.corr(method='spearman'), vmin=-1, vmax=1, annot=True, cmap=\"coolwarm\")\n",
    "plt.title(\"Spearman Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b44c4bdf-8114-4f95-86b5-9020949d6c80",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Group by all columns and count occurrences\n",
    "\n",
    "duplicate_groups = df_joined.groupBy(df_joined.columns) \\\n",
    "    .count() \\\n",
    "    .filter(\"count > 1\")\\\n",
    "    .drop(\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62f59ba2-e27b-4cb2-b0ef-cb6849d92140",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "duplicate_groups.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f101408a-c73c-4e92-9f1a-a135deac52ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_joined = df_joined.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7cc039a-6ccf-4f29-a553-c920b932e86d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, sum as spark_sum\n",
    "\n",
    "# Join duplicates with original DataFrame to get duplicate rows (excluding first)\n",
    "duplicate_rows = df_joined.join(duplicate_groups,on=df_joined.columns, how='inner')\n",
    "\n",
    "# Sum all numeric columns over duplicate rows\n",
    "numeric_cols = [field.name for field in df_joined.schema.fields if isinstance(field.dataType, (IntegerType, DoubleType, LongType, FloatType))]\n",
    "\n",
    "sum_exprs = [spark_sum(col(c)).alias(c) for c in numeric_cols]\n",
    "\n",
    "duplicate_sums = duplicate_rows.agg(*sum_exprs)\n",
    "\n",
    "duplicate_sums.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3f71532-19b3-4c98-a87b-801c295a3bf4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import col, count, lit\n",
    "\n",
    "# Define the subset columns used to detect duplicates\n",
    "subset_cols = [\n",
    "    \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\", \"RatecodeID\",\n",
    "    \"PULocationID\", \"DOLocationID\", \"passenger_count\", \"trip_distance\"\n",
    "]\n",
    "\n",
    "# Define a window partitioned by subset columns\n",
    "window_spec = Window.partitionBy([col(c) for c in subset_cols])\n",
    "\n",
    "# Add a count column that counts how many rows share the same values in subset_cols\n",
    "df_with_dup_count = df_joined.withColumn(\"dup_count\", count(\"*\").over(window_spec))\n",
    "\n",
    "# Filter rows where dup_count > 1 (i.e., duplicates including the first occurrence)\n",
    "duplicate_value = df_with_dup_count.filter(col(\"dup_count\") > 1).drop(\"dup_count\")\n",
    "\n",
    "duplicate_value.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb96742b-31a8-430b-995e-9fccd7010782",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Filter negative fare_amount values from duplicates\n",
    "dup_negatif_val = duplicate_value.filter(col(\"fare_amount\") < 0)\n",
    "\n",
    "dup_negatif_val.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e8ca553-66ac-4717-b605-fb386af0e4a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# joins the two DataFrames and keeps only those rows from df_joined that do not exist in dup_negatif_val.\n",
    "df_joined = df_joined.join(dup_negatif_val, on=df_joined.columns, how='left_anti')\n",
    "\n",
    "df_joined.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a79a7fd-6def-4dfa-883c-cc1aad48f9cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# from pyspark.sql.window import Window\n",
    "# from pyspark.sql.functions import row_number\n",
    "\n",
    "# # Define subset columns for duplicate detection\n",
    "# subset_cols = [\n",
    "#     \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\", \"RatecodeID\",\n",
    "#     \"PULocationID\", \"DOLocationID\", \"passenger_count\", \"trip_distance\"\n",
    "# ]\n",
    "\n",
    "# # Define a window partitioned by the subset columns and ordered arbitrarily\n",
    "# window_spec = Window.partitionBy(*subset_cols).orderBy(\"tpep_pickup_datetime\")\n",
    "\n",
    "# # Add a row number to identify duplicates\n",
    "# df_with_row_num = df_joined.withColumn(\"row_num\", row_number().over(window_spec))\n",
    "\n",
    "# # Filter to get only the duplicate entries (i.e., row number > 1)\n",
    "# df_duplicates_only = df_with_row_num.filter(\"row_num > 1\")\n",
    "\n",
    "# # df_duplicates_only.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "968f226d-1a58-4d08-a3b1-3e3c36d7d4bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Negative Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02cbad5d-d3ba-4a9b-b222-b51f9d34cec9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when, count, lit\n",
    "from pyspark.sql.types import NumericType\n",
    "\n",
    "# Get numeric columns\n",
    "numeric_cols = [field.name for field in df_joined.schema.fields if isinstance(field.dataType, NumericType)]\n",
    "\n",
    "# Total number of rows\n",
    "total_rows = df_joined.count()\n",
    "\n",
    "# Create a list to collect results\n",
    "neg_percent_list = []\n",
    "\n",
    "# Loop through numeric columns and compute % of negative values\n",
    "for col_name in numeric_cols:\n",
    "    neg_count = df_joined.filter(col(col_name) < 0).count()\n",
    "    neg_percent = __builtins__.round((neg_count / total_rows) * 100, 3)\n",
    "    neg_percent_list.append((col_name, neg_percent))\n",
    "\n",
    "# Create a DataFrame from the result\n",
    "neg_percent_df = spark.createDataFrame(neg_percent_list, [\"feature\", \"neg_value(%)\"])\n",
    "\n",
    "neg_percent_df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a1cb2ed-f1a1-4d83-8739-aaa6c3c0a729",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Replace negative fare_amounts with their absolute value\n",
    "df_joined = df_joined.withColumn(\n",
    "    \"fare_amount\",\n",
    "    when(col(\"fare_amount\") < 0, abs(col(\"fare_amount\"))).otherwise(col(\"fare_amount\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ddda1ecc-ef93-4862-942e-e45ded5720aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Zero Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9b96af1-cfaf-4a6d-9d9d-c324b5dcc350",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import NumericType\n",
    "\n",
    "# Get numeric columns with their data types\n",
    "numeric_fields = [(f.name, f.dataType.simpleString()) for f in df_joined.schema.fields if isinstance(f.dataType, NumericType)]\n",
    "\n",
    "# Total number of rows\n",
    "total_rows = df_joined.count()\n",
    "\n",
    "# List to collect results\n",
    "zero_value_stats = []\n",
    "\n",
    "# Loop through numeric columns and calculate % of zero values\n",
    "for col_name, dtype in numeric_fields:\n",
    "    zero_count = df_joined.filter(col(col_name) == 0).count()\n",
    "    zero_percent = __builtins__.round((zero_count / total_rows) * 100, 3)\n",
    "    zero_value_stats.append((col_name, dtype, zero_percent))\n",
    "\n",
    "# Create a DataFrame from results\n",
    "zero_value_df = spark.createDataFrame(zero_value_stats, [\"feature\", \"data_type\", \"0_value(%)\"])\n",
    "\n",
    "# Show result\n",
    "zero_value_df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95584816-f1ab-4a32-8f82-f5588aab03a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, expr\n",
    "\n",
    "# Step 1: Calculate median (approximate) for passenger_count\n",
    "median_passenger_count = df_joined.approxQuantile(\"passenger_count\", [0.5], 0.01)[0]\n",
    "\n",
    "# Step 2: Replace passenger_count = 0 with median\n",
    "df_joined = df_joined.withColumn(\n",
    "    \"passenger_count\",\n",
    "    expr(f\"CASE WHEN passenger_count = 0 THEN {median_passenger_count} ELSE passenger_count END\")\n",
    ")\n",
    "\n",
    "# Step 3: Filter rows with trip_distance > 0\n",
    "df_joined = df_joined.filter(col(\"trip_distance\") > 0)\n",
    "\n",
    "# Step 4: Filter rows with fare_amount > 0\n",
    "df_joined = df_joined.filter(col(\"fare_amount\") > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1ba4553a-6b15-47b8-9e48-6d22dffdb455",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6da3ec17-d30c-4dbd-9618-545d28a58b0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, count, when, isnan\n",
    "from pyspark.sql.types import DoubleType, FloatType, NumericType\n",
    "\n",
    "# Total number of rows\n",
    "total_rows = df_joined.count()\n",
    "\n",
    "null_summary = []\n",
    "\n",
    "for column, dtype in df_joined.dtypes:\n",
    "    # Check if column is numeric (so we can safely apply isnan)\n",
    "    is_numeric = dtype in ['double', 'float']\n",
    "\n",
    "    # Apply isnan only to numeric columns\n",
    "    if is_numeric:\n",
    "        null_count = df_joined.filter(col(column).isNull() | isnan(col(column))).count()\n",
    "    else:\n",
    "        null_count = df_joined.filter(col(column).isNull()).count()\n",
    "\n",
    "    null_percent = __builtins__.round((null_count / total_rows) * 100, 3)\n",
    "    \n",
    "    null_summary.append((column, dtype, null_percent))\n",
    "\n",
    "# Create summary DataFrame\n",
    "null_summary_df = spark.createDataFrame(null_summary, [\"feature\", \"data_type\", \"null_value(%)\"])\n",
    "null_summary_df.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "26badf59-099b-4fc3-8946-216f6b13ad63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Handling RateCodeID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94fda02c-08cb-48df-badb-e86c150ad178",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_joined.groupBy(\"RatecodeID\").count().orderBy(\"count\", ascending=False).display()\n",
    "# df_joined.groupBy(\"RatecodeID\").count().orderBy(\"count\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d507e37a-c983-4f1c-952d-c5a8d7f4e73d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_joined = df_joined.replace(\"N/A\", \"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0745abd5-a7e4-4cb2-89d3-6c286831c3d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_joined.filter(col(\"RatecodeID\") == 4) \\\n",
    "    .groupBy(\"PUBorough\", \"DOBorough\") \\\n",
    "    .count() \\\n",
    "    .orderBy(\"count\", ascending=False) \\\n",
    "    .display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b30d8b50-3d57-440c-adc7-e95818df30ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Apply conditional updates to RatecodeID\n",
    "df_joined = df_joined.withColumn(\n",
    "    \"RatecodeID\",\n",
    "    when(\n",
    "        (col(\"RatecodeID\") == 4) &\n",
    "        (col(\"PUBorough\") != \"Unknown\") &\n",
    "        (col(\"DOBorough\") == \"EWR\"),\n",
    "        3\n",
    "    ).when(\n",
    "        (col(\"RatecodeID\") == 4) &\n",
    "        (col(\"PUBorough\") != \"Unknown\") &\n",
    "        (col(\"DOBorough\") != \"Unknown\"),\n",
    "        1\n",
    "    ).otherwise(col(\"RatecodeID\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba9b9e89-4fdd-4047-8212-3c62b4ea93de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Remove rows where either PUBorough or DOBorough is 'Unknown'\n",
    "df_joined = df_joined.filter(\n",
    "    (col(\"PUBorough\") != \"Unknown\") & (col(\"DOBorough\") != \"Unknown\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d2d86c2-e847-4363-9125-9c7da9cfe69d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 1: Replace 99 with null in RatecodeID\n",
    "df_joined = df_joined.withColumn(\n",
    "    \"RatecodeID\",\n",
    "    when(col(\"RatecodeID\") == 99, None).otherwise(col(\"RatecodeID\"))\n",
    ")\n",
    "\n",
    "# Step 2: Update RatecodeID based on custom conditions\n",
    "df_joined = df_joined.withColumn(\n",
    "    \"RatecodeID\",\n",
    "    when(\n",
    "        (col(\"RatecodeID\").isNull()) &\n",
    "        (col(\"PUBorough\") == \"Manhattan\") &\n",
    "        (col(\"DOZone\") == \"JFK Airport\"),\n",
    "        2\n",
    "    ).when(\n",
    "        (col(\"RatecodeID\").isNull()) &\n",
    "        (col(\"PUZone\") == \"JFK Airport\") &\n",
    "        (col(\"DOBorough\") == \"Manhattan\"),\n",
    "        2\n",
    "    ).when(\n",
    "        (col(\"RatecodeID\").isNull()) &\n",
    "        (col(\"DOZone\") == \"Newark Airport\"),\n",
    "        3\n",
    "    ).otherwise(col(\"RatecodeID\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d159c03f-a508-4e04-87fe-bce3f45937c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Fill nulls in RatecodeID with 1\n",
    "df_joined = df_joined.withColumn(\n",
    "    \"RatecodeID\",\n",
    "    when(col(\"RatecodeID\").isNull(), 1).otherwise(col(\"RatecodeID\"))\n",
    ")\n",
    "\n",
    "# Show value counts for RatecodeID\n",
    "df_joined.groupBy(\"RatecodeID\").count().orderBy(\"RatecodeID\").show()\n",
    "\n",
    "# Count total remaining nulls in RatecodeID (should be 0)\n",
    "null_count = df_joined.filter(col(\"RatecodeID\").isNull()).count()\n",
    "print(\"Total NaN values: \", null_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c926a47d-6440-4988-b9f3-5db36259170c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Filling missing values in the passenger count with the median value of that feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48e40a87-e8da-43bc-8b44-469c311b01fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 1: Calculate median of passenger_count\n",
    "median_value = df_joined.approxQuantile(\"passenger_count\", [0.5], 0.0)[0]\n",
    "\n",
    "# Step 2: Fill nulls with median value\n",
    "df_joined = df_joined.withColumn(\n",
    "    \"passenger_count\",\n",
    "    when(col(\"passenger_count\").isNull(), median_value).otherwise(col(\"passenger_count\"))\n",
    ")\n",
    "\n",
    "# Step 3: Show value counts for passenger_count\n",
    "df_joined.groupBy(\"passenger_count\").count().orderBy(\"passenger_count\").display()\n",
    "\n",
    "# Step 4: Count remaining nulls in passenger_count\n",
    "null_count = df_joined.filter(col(\"passenger_count\").isNull()).count()\n",
    "print(\"Total NaN values: \", null_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d2a6800b-2932-49c1-a770-fdabb84f10b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Handling Payment Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4fa60cea-dc66-4d56-b550-db8ae332bca9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1. Count of each payment_type (excluding nulls)\n",
    "df_joined.groupBy(\"payment_type\").count().orderBy(\"count\", ascending=False).show()\n",
    "\n",
    "# 2. Count of null values in payment_type\n",
    "null_count = df_joined.filter(col(\"payment_type\").isNull()).count()\n",
    "print(\"Total NaN values:\", null_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee32c9db-273b-44c2-bc77-30c86e7cd407",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_joined.filter(col(\"tip_amount\") > 0) \\\n",
    "    .groupBy(\"payment_type\") \\\n",
    "    .count() \\\n",
    "    .orderBy(\"count\", ascending=False) \\\n",
    "    .display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c169bf5f-6444-4a5a-b7e1-905b0eeee0c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 1: Update payment_type from 2 to 1 where tip_amount > 0\n",
    "df_joined = df_joined.withColumn(\n",
    "    \"payment_type\",\n",
    "    when((col(\"tip_amount\") > 0) & (col(\"payment_type\") == 2), 1).otherwise(col(\"payment_type\"))\n",
    ")\n",
    "\n",
    "# Step 2: Count of payment_type where tip_amount > 0\n",
    "df_joined.filter(col(\"tip_amount\") > 0) \\\n",
    "    .groupBy(\"payment_type\") \\\n",
    "    .count() \\\n",
    "    .orderBy(\"count\", ascending=False) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fef88a9d-29a9-4e85-8dc4-e24119a581b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_joined = df_joined.withColumn(\n",
    "    \"payment_type\",\n",
    "    when(isnull(col(\"payment_type\")), when(col(\"tip_amount\") > 0, 1.0).otherwise(5.0))\n",
    "    .otherwise(col(\"payment_type\"))\n",
    ")\n",
    "\n",
    "df_joined.groupBy(\"payment_type\").count().orderBy(\"count\", ascending=False).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56b34bcd-89f6-463f-8b10-e64c9a97332c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Total data:\", df_joined.count())\n",
    "df_joined.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45969197-4d80-4635-9863-09b235b3300e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Be careful with large datasets — consider limiting rows\n",
    "df_pd = df_joined.limit(10000).toPandas()\n",
    "msno.matrix(df_pd, figsize=(20, 6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "de399291-c2db-4fe3-8f25-7fa27bb288b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Formatting and Outlier Handling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d9a02739-c72b-4c52-b85d-42a5c5ca243b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Pickup and Dropoff Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af86e0a9-fa05-4ed3-93c2-992c6c889839",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df_joined = df_joined.withColumn(\"tpep_pickup_datetime\", to_timestamp(\"tpep_pickup_datetime\"))\n",
    "df_joined = df_joined.withColumn(\"tpep_dropoff_datetime\", to_timestamp(\"tpep_dropoff_datetime\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e556a08f-401c-499a-a8d0-a63e4603cf88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "outliers = df_joined.filter(\n",
    "    ~(\n",
    "        (year(col(\"tpep_pickup_datetime\")) == 2016) &\n",
    "        (month(col(\"tpep_pickup_datetime\")).isin([1, 2, 3]))\n",
    "    )\n",
    ")\n",
    "\n",
    "outliers.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "50bd450c-1c19-431b-8a4e-9cd61c2283b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### Adding columns according to hours(midnight,morning,evening) and Weekdays/Weekend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f9ddd5b-97f2-4262-8bee-3186c17b7eff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define pickup_time by binning hour of day into categorical time labels\n",
    "df_joined = df_joined.withColumn(\n",
    "    \"pickup_hour\",\n",
    "    hour(col(\"tpep_pickup_datetime\"))\n",
    ")\n",
    "\n",
    "df_joined = df_joined.withColumn(\n",
    "    \"pickup_time\",\n",
    "    when((col(\"pickup_hour\") >= 0) & (col(\"pickup_hour\") < 5), \"Midnight\")\n",
    "    .when((col(\"pickup_hour\") >= 5) & (col(\"pickup_hour\") < 11), \"Morning\")\n",
    "    .when((col(\"pickup_hour\") >= 11) & (col(\"pickup_hour\") < 15), \"Noon\")\n",
    "    .when((col(\"pickup_hour\") >= 15) & (col(\"pickup_hour\") < 20), \"Evening\")\n",
    "    .when((col(\"pickup_hour\") >= 20) & (col(\"pickup_hour\") < 24), \"Night\")\n",
    "    .otherwise(\"Unknown\")\n",
    ")\n",
    "\n",
    "# Create day_category column to mark 'Weekend' or 'Weekdays'\n",
    "df_joined = df_joined.withColumn(\n",
    "    \"day_name\",\n",
    "    date_format(col(\"tpep_pickup_datetime\"), \"EEEE\")  # full day name like Monday, Tuesday\n",
    ")\n",
    "\n",
    "df_joined = df_joined.withColumn(\n",
    "    \"day_category\",\n",
    "    when(col(\"day_name\").isin(\"Saturday\", \"Sunday\"), \"Weekend\").otherwise(\"Weekdays\")\n",
    ")\n",
    "\n",
    "# Optional: Drop intermediate 'pickup_hour' and 'day_name' if you want\n",
    "df_joined = df_joined.drop(\"pickup_hour\", \"day_name\")\n",
    "\n",
    "df_joined.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2fcc4cc4-d2a8-4fae-a313-244ccbd8da64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### RateCodeID "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69f7907a-8a0d-42e3-a0ef-a5a60e53e19c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_joined = df_joined.withColumn(\n",
    "    \"RatecodeID\",\n",
    "    when(col(\"RatecodeID\") == 1, \"Standard rate\")\n",
    "    .when(col(\"RatecodeID\") == 2, \"JFK Airport\")\n",
    "    .when(col(\"RatecodeID\") == 3, \"Newark Airport\")\n",
    "    .when(col(\"RatecodeID\") == 4, \"Nassau or Westchester\")\n",
    "    .when(col(\"RatecodeID\") == 5, \"Negotiated fare\")\n",
    "    .when(col(\"RatecodeID\") == 6, \"Group ride\")\n",
    "    .otherwise(col(\"RatecodeID\"))  # keep original if none of above\n",
    ")\n",
    "\n",
    "# To count occurrences like value_counts():\n",
    "df_joined.groupBy(\"RatecodeID\").count().orderBy(\"count\", ascending=False).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6bf9942-6cdb-4447-bc22-e6051bc7a5cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_joined.groupBy(\"passenger_count\").count().orderBy(\"count\", ascending=False).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f23868eb-d62d-41ec-8278-837bc407324f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Collect passenger_count as a Pandas DataFrame (or Series)\n",
    "pdf = df_joined.select(\"passenger_count\").toPandas()\n",
    "\n",
    "plt.figure(figsize=(15, 3))\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "sns.boxplot(data=pdf, x='passenger_count', color='skyblue')  # You can replace 'skyblue' with your color[0]\n",
    "plt.xlabel('Total Passenger')\n",
    "plt.title('Passenger Distribution', fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "98449161-a919-4dfb-a30d-58163c6ce9c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###### The maximum amount of passengers allowed in a yellow taxicab by law is four (4) in a four (4) passenger taxicab or five (5) passengers in a five (5) passenger taxicab. All passengers must wear seat belts and children under the age of 4 must ride in child safety seats. Children under the age of 8 must ride in a child restraint system, such as a federally approved harness, vest, or booster-seat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8340ee8-b4ef-4f71-9150-e50c5ec75e59",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convert passenger_count to a string and group values >5 into '>5'\n",
    "df_joined = df_joined.withColumn(\n",
    "    \"passenger_count\",\n",
    "    when(col(\"passenger_count\") > 5, \">5\").otherwise(col(\"passenger_count\").cast(\"string\"))\n",
    ")\n",
    "\n",
    "# Count the transformed values\n",
    "df_joined.groupBy(\"passenger_count\").count().orderBy(\"count\", ascending=False).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e3f648ad-c7ff-458d-80a8-ebf88e95361e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Trip distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35418a97-ab96-47ad-95fa-2486181aa9e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_sample = df_joined.select(\"trip_distance\").sample(fraction=0.01).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f1d9bcb-967c-4657-963e-49862b7bfc6e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 3))\n",
    "sns.boxplot(data=df_sample, x='trip_distance', color='#1f77b4')  # You can replace with your color\n",
    "plt.xlabel('Distance (mile)')\n",
    "plt.title('Trip Distance Distribution', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4dc0b1ff-d42a-464d-8306-d659c4bd32c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### Based on the assumption that taxi trips covering a distance of less than 1 km (0.62 miles) are considered abnormal records or failed trips — such as possible cancellations by passengers or drivers — the dataset entries with such values will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed8047b4-fe57-4a30-a6e1-4ed8f5e1bd6d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Count number of rows with trip distance less than 0.62\n",
    "count_short_trips = df_joined.filter(col(\"trip_distance\") < 0.62).count()\n",
    "print(\"Number of records with trip distance < 1 km (0.62 miles):\", count_short_trips)\n",
    "\n",
    "# Filter out short-distance trips\n",
    "df_joined = df_joined.filter(col(\"trip_distance\") > 0.62)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2818ab13-7c99-45a7-b987-0e97e7d99991",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### \t•\tThere are extreme outliers in the taxi trip distance data.\n",
    "•\tFirst, handle those extreme outliers before continuing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b92e2efa-6618-48d4-8727-6f9c392bc973",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Filter for trip_distance > 50\n",
    "df_joined.filter(col('trip_distance') > 50) \\\n",
    "  .select('tpep_pickup_datetime', 'tpep_dropoff_datetime', 'PULocationID', 'DOLocationID', 'trip_distance', 'fare_amount') \\\n",
    "  .orderBy(col('trip_distance').asc()) \\\n",
    "  .display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "73506228-f442-449d-842b-89675fa0a607",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### \t•\tIt can be seen from the extreme outlier data above that there are distances greater than 120 miles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7017f8ce-0c7a-4318-9bf5-bdfb8c10fc16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Filter rows where trip_distance > 50 and select columns\n",
    "outliers = df_joined.filter(col(\"trip_distance\") > 50) \\\n",
    "                    .select(\"PULocationID\", \"DOLocationID\", \"trip_distance\")\n",
    "\n",
    "# Count total outliers\n",
    "total_outliers = outliers.count()\n",
    "print(\"Total outliers:\", total_outliers)\n",
    "\n",
    "# Show first few rows\n",
    "outliers.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2dd520af-6589-48df-91a9-2a86fee98ca3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### We will try to replace the extreme outlier data above with the central tendency value (median) of trip_distance for each combination of pickup and dropoff locations in the existing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69fb72d5-d1fb-43d1-8277-724d0562b9da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Filter out extreme outliers (trip_distance < 50)\n",
    "df_filtered = df_joined.filter(col('trip_distance') < 50)\n",
    "\n",
    "# Compute count, average, and median of trip_distance grouped by PULocationID and DOLocationID\n",
    "ct_distance_byid = df_filtered.groupBy('PULocationID', 'DOLocationID').agg(\n",
    "    count('trip_distance').alias('count'),\n",
    "    mean('trip_distance').alias('avg_distance'),\n",
    "    expr('percentile_approx(trip_distance, 0.5)').alias('median_distance')\n",
    ")\n",
    "\n",
    "\n",
    "ct_distance_byid.orderBy(rand()).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17fe22c2-f300-4142-a7ff-0244b63159b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Join outliers with median distance table on PU and DO location IDs\n",
    "distance_byid = outliers.join(\n",
    "    ct_distance_byid.drop('count'), \n",
    "    on=['PULocationID', 'DOLocationID'],\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35e02fc1-c018-429d-a7d8-f0b07cbde4af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Join df_joined with distance_byid to get median values where needed\n",
    "df_with_median = df_joined.join(\n",
    "    distance_byid.select('PULocationID', 'DOLocationID', 'median_distance'),\n",
    "    on=['PULocationID', 'DOLocationID'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Replace trip_distance with median_distance for outliers (where trip_distance > 50)\n",
    "df_imputed = df_with_median.withColumn(\n",
    "    'trip_distance',\n",
    "    when(col('trip_distance') > 50, col('median_distance')).otherwise(col('trip_distance'))\n",
    ").drop('median_distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a82758cf-0dcb-4f39-ae73-b29350c14878",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_imputed.select('PULocationID', 'DOLocationID', 'trip_distance').filter(col('trip_distance') <= 50).display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26dcdfc5-3972-4809-802a-bb0e4f309f74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_joined = df_imputed\n",
    "df_joined.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a4f1499f-5831-4c97-b464-e6acab1bb851",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### There are several entries that do not have matching Location ID records in the dataset, which will result in NaN values during imputation.\n",
    "•\tTo handle this issue, a method similar to the previous one will be used. However, this time, the median value will be calculated based on Borough-level (region-level) instead of Location ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ee4841f-449a-4e74-b8d7-81d6726973a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "isna = df_joined.filter(col(\"trip_distance\").isNull()) \\\n",
    "                .select(\"PUBorough\", \"DOBorough\", \"trip_distance\")\n",
    "isna.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52a58e90-3d76-44ed-8014-c81f8e4449f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Filter data with trip_distance < 70\n",
    "df_filtered = df_joined.filter(col(\"trip_distance\") < 70)\n",
    "\n",
    "# Group by PUBorough and DOBorough and compute count, mean, median\n",
    "ct_distance_byborough = df_filtered.groupBy(\"PUBorough\", \"DOBorough\").agg(\n",
    "    count(\"trip_distance\").alias(\"count\"),\n",
    "    avg(\"trip_distance\").alias(\"avg_distance\"),\n",
    "    expr(\"percentile_approx(trip_distance, 0.5)\").alias(\"median_distance\")\n",
    ")\n",
    "\n",
    "# ct_distance_byborough.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbb28f52-5a09-4e68-b19c-bd5bfb4a7565",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 2: Join with ct_distance_byborough to get median_distance for each borough pair\n",
    "distance_byborough = isna.join(\n",
    "    ct_distance_byborough.select(\"PUBorough\", \"DOBorough\", \"median_distance\"),\n",
    "    on=[\"PUBorough\", \"DOBorough\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Step 3: Perform the imputation (replace null trip_distance with median_distance)\n",
    "df_with_median = df_joined.join(\n",
    "    ct_distance_byborough.select(\"PUBorough\", \"DOBorough\", \"median_distance\"),\n",
    "    on=[\"PUBorough\", \"DOBorough\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "df_imputed = df_with_median.withColumn(\n",
    "    \"trip_distance\",\n",
    "    when(col(\"trip_distance\").isNull(), expr(\"round(median_distance, 2)\"))\n",
    "    .otherwise(col(\"trip_distance\"))\n",
    ").drop(\"median_distance\")  # Drop helper column\n",
    "\n",
    "# Optional: Inspect newly imputed rows\n",
    "# print(\"Input Results:\")\n",
    "# df_imputed.filter(col(\"trip_distance\").isNotNull() & col(\"median_distance\").isNotNull()) \\\n",
    "#           .select(\"PUBorough\", \"DOBorough\", \"trip_distance\") \\\n",
    "#           .show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07766e49-f097-4492-8af4-e63b08489a17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_joined = df_imputed\n",
    "df_joined.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0359101f-8190-44f1-9dba-96cde2bac968",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Feature Creation adding driving speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66397af7-c523-4eb6-99a5-aeb89f3e38e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df_joined = df_joined.withColumn(\n",
    "    \"speed\",\n",
    "    round(col(\"trip_distance\") / (col(\"trip_duration\") / 60), 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f94128a4-1aa0-4399-aea4-9f3a3f8c3dbf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_joined.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "219f96c6-ec3f-44a1-ba01-66b33ab2654b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "first_three",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}